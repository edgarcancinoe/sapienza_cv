{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j78LyEcyj5ds",
        "OKJ438WuPrbW",
        "lBOtlcrzQzft",
        "S5yDKZK-itMd",
        "97YgdIimmq--",
        "5seQ6pkrrKhE",
        "Mrei-Y8LGNbg",
        "hV4cGYrKvHlt",
        "tW1NTfxGQozV",
        "zxWVBEYzoT83",
        "XeRZ4LPypori",
        "KwQ7KYp4qgRY",
        "0uoMmyijrSCX",
        "K9VW8aa23-Mh",
        "vTkyLXE84zTx",
        "sLlfHD_7OWuP",
        "rzpV7kMBcLDZ",
        "5i_HxSshZTO5",
        "ITlA2PEY12E7",
        "L1-k_iVSfsfs",
        "9nIzvA2mwOsd",
        "rvjWAyocHkYl",
        "l8A4FBr14MNx",
        "Wwzin-DM2PiY",
        "hZ5nnDAX1jdz",
        "EqSGKrSuDLqB",
        "NiILerMxfCbY",
        "jxmXM3DFah-M"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edgarcancinoe/sapienza_cv/blob/main/vision_tutorial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "j78LyEcyj5ds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš ï¸ Important: Read Before Running  \n",
        "\n",
        "This notebook is set to **execution-only mode**, meaning you can **run all the cells**, but you **cannot modify** the code directly.  \n",
        "\n",
        "If you want to **edit** or **test your own modifications**, follow these steps:  \n",
        "\n",
        "1ï¸âƒ£ **Go to**: `File` â†’ `Save a copy in Drive`  \n",
        "2ï¸âƒ£ This will create a **personal copy** of the notebook in your own Google Drive.  \n",
        "3ï¸âƒ£ You can now **edit and experiment freely** without affecting the original notebook.  \n",
        "\n",
        "This ensures that everyone has access to a clean and structured version of the notebook while allowing individual experimentation ðŸš€"
      ],
      "metadata": {
        "id": "OKJ438WuPrbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.image as mpim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import random\n",
        "import requests\n",
        "import urllib.request\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from io import BytesIO\n",
        "from IPython.display import display, clear_output\n",
        "from ipywidgets import interact, IntSlider, FloatSlider, FloatRangeSlider, Dropdown\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from matplotlib.patches import FancyArrowPatch\n",
        "from PIL import Image\n",
        "from prettytable import PrettyTable\n",
        "from scipy import signal\n",
        "from scipy.fft import fft, fftfreq, fftshift\n",
        "from skimage import io, color"
      ],
      "metadata": {
        "id": "CjXfxayEj1pG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image loading"
      ],
      "metadata": {
        "id": "lBOtlcrzQzft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load an image from the web and use it as test image for our experiments"
      ],
      "metadata": {
        "id": "W24BoG7_Q3Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O image.jpg \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Colosseo_2020.jpg/1200px-Colosseo_2020.jpg\""
      ],
      "metadata": {
        "id": "6ld6A81Ga_b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the image with OpenCV"
      ],
      "metadata": {
        "id": "QyesijBMbs7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"image.jpg\")\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "_QOGqtcVkLqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the image through Matplotlib"
      ],
      "metadata": {
        "id": "3uvLqtOfR0yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G1MyE3XOoiU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we see the image with altered colors?\n",
        "\n",
        "Because OpenCV stores the images in the BGR format.\n",
        "\n",
        "We need to treat it in RGB format with Matplotlib"
      ],
      "metadata": {
        "id": "tui5SqhEcQAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b,g,r = cv2.split(image)\n",
        "rgb_image = cv2.merge([r,g,b])"
      ],
      "metadata": {
        "id": "RfV43QjQcXHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisualize it!"
      ],
      "metadata": {
        "id": "105aTHsAdEh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(rgb_image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "image = rgb_image"
      ],
      "metadata": {
        "id": "-OZNNe58dDJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image filtering"
      ],
      "metadata": {
        "id": "S5yDKZK-itMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering: Form a new image whose pixel values are a combination of\n",
        "the original pixel values.\n",
        "\n",
        "\n",
        "It is used to:\n",
        "- Remove noise\n",
        "- Detect edges\n",
        "- Blur the image\n"
      ],
      "metadata": {
        "id": "6__rhyrmsLWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean filter"
      ],
      "metadata": {
        "id": "97YgdIimmq--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Mean Filter is a simple smoothing filter that replaces each pixelâ€™s value\n",
        "with the average of its neighboring pixels by usign a kernel. The higher the kernel size, the higher the blur in the resulting image.\n",
        "\n",
        "$$h[x,y] = \\frac{1}{N}\\sum_{i,j}f[x+i,y+j]$$\n",
        "\n",
        "where:\n",
        "- $i$ is the original image\n",
        "- $h[x,y]$ is the output pixel value at location $(x,y)$\n",
        "- $N$ is the total number of pixels in the kernel\n",
        "\n",
        "The kernel must be odd to have a well-defined central pixel in the kernel, making calculations symmetrical.\n",
        "\n",
        "Properties:\n",
        "- blurring âœ…\n",
        "- no edge preservation âŒ"
      ],
      "metadata": {
        "id": "JCgE1-y5oC6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f76GX5XeM1J"
      },
      "outputs": [],
      "source": [
        "mean_kernel_slider = widgets.IntSlider(value=5, min=3, max=21, step=2, description=\"Kernel Size\")\n",
        "\n",
        "def mean_filter(kernel_size):\n",
        "    # apply Mean Filter\n",
        "    mean_filtered = cv2.blur(image, (kernel_size, kernel_size))\n",
        "\n",
        "    plt.figure(figsize=(18,8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(mean_filtered)\n",
        "    plt.title(f\"Mean Filter (Kernel={kernel_size}x{kernel_size})\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "interactive_mean = widgets.interactive(mean_filter, kernel_size=mean_kernel_slider)\n",
        "display(interactive_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian filter"
      ],
      "metadata": {
        "id": "5seQ6pkrrKhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gaussian Filter is similar to the Mean Filter, but instead of averaging all pixels equally, it applies a weighted average where nearby pixels have higher importance.\n",
        "\n",
        "$$h[m,n] = \\sum_{k,l}g[k,l]f[m+k,n+l]$$\n",
        "\n",
        "The kernel must be odd to have a well-defined central pixel in the kernel, making calculations symmetrical\n",
        "\n",
        "where:\n",
        "- $h$ is the output image\n",
        "- $g$ is the spatial weghting to favro nearby pixels\n",
        "- $f$ is the original image\n",
        "\n",
        "Properties:\n",
        "- smoother blurring âœ…\n",
        "- small edge preservation ðŸ˜"
      ],
      "metadata": {
        "id": "YwkJR52bFN6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gaussian_kernel_slider = widgets.IntSlider(value=5, min=3, max=21, step=2, description=\"Kernel Size\")\n",
        "\n",
        "def gaussian_filter(kernel_size):\n",
        "    # apply Gaussian Filter\n",
        "    gaussian_filtered = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    plt.figure(figsize=(18,8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(gaussian_filtered)\n",
        "    plt.title(f\"Gaussian Filter (Kernel={kernel_size}x{kernel_size})\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "interactive_gaussian = widgets.interactive(gaussian_filter, kernel_size=gaussian_kernel_slider)\n",
        "display(interactive_gaussian)"
      ],
      "metadata": {
        "id": "dWZyb43HrMpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bilateral filter"
      ],
      "metadata": {
        "id": "Mrei-Y8LGNbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bilateral Filter is a non-linear, edge-preserving, and noise-reducing filter. Unlike Mean and Gaussian filters, which blur edges, the Bilateral Filter smooths noise while keeping edges sharp. Nearby pixels contribute more (like Gaussian filtering). Pixels with similar intensity contribute more (preserving edges).\n",
        "\n",
        "**Remember**: edges are characterized by rapid intensity change in the image\n",
        "\n",
        "$$h[m,n] = \\frac{1}{W_{mn}}\\sum_{k,l}g[k,l]r_{mn}[k,l]f[m+k,n+l]$$\n",
        "\n",
        "where:\n",
        "- $h$ is the output image\n",
        "- $g$ is the spatial weighting to favor *nearby* pixels\n",
        "- $r$ is the intensity range weighting to favor *similar* pixels\n",
        "- $\\frac{1}{W_{mn}}$ is a normalization factor\n",
        "- $f$ is the original image\n",
        "\n",
        "Properties:\n",
        "- smooth blurring âœ…\n",
        "- edge preservation âœ…\n",
        "\n",
        "bilateralFilter function Parameters:\n",
        "\n",
        "- Diameter: Size of the pixel neighborhood used for filtering. A larger d means more neighboring pixels influence the smoothing.\n",
        "\n",
        "- Sigma Color: How much intensity differences matter. Higher values mean stronger smoothing, even for pixels with large intensity differences.\n",
        "\n",
        "\n",
        "- Sigma Space: How much spatial distance matters. Higher values allow more distant pixels to influence the smoothing.\n"
      ],
      "metadata": {
        "id": "kL3MOpR9GcGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diameter_slider = widgets.IntSlider(value=9, min=1, max=20, step=2, description=\"Diameter\")\n",
        "sigma_color_slider = widgets.IntSlider(value=75, min=10, max=200, step=5, description=\"Sigma Color\")\n",
        "sigma_space_slider = widgets.IntSlider(value=75, min=10, max=200, step=5, description=\"Sigma Space\")\n",
        "\n",
        "def bilateral_filter(diameter, sigma_color, sigma_space):\n",
        "  # apply Bilateral Filter\n",
        "    bilateral_filtered = cv2.bilateralFilter(image, diameter, sigma_color, sigma_space)\n",
        "\n",
        "    plt.figure(figsize=(18,8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(bilateral_filtered)\n",
        "    plt.title(f\"Bilateral Filter (d={diameter}, Ïƒc={sigma_color}, Ïƒs={sigma_space})\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "interactive_plot = widgets.interactive(bilateral_filter,\n",
        "                                       diameter=diameter_slider,\n",
        "                                       sigma_color=sigma_color_slider,\n",
        "                                       sigma_space=sigma_space_slider)\n",
        "display(interactive_plot)"
      ],
      "metadata": {
        "id": "IwciOk4AHERJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution (nothing else than what done so far)"
      ],
      "metadata": {
        "id": "hV4cGYrKvHlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution is a fundamental operation in image processing, commonly used for filtering, edge detection, sharpening, blurring, and feature extraction. It involves sliding a small matrix (called a kernel or filter) over an image and computing the sum of element-wise multiplications between the kernel and the corresponding region of the image.\n",
        "\n",
        "$$g = h \\star i  \\quad  \\rightarrow \\quad g[x,y] = \\sum_{u=-k}^{k}\\sum_{v=-k}^{k}h[u,v]\\,i[x-u,y-v]$$\n",
        "\n",
        "where:\n",
        "- $i$ is the image\n",
        "- $h$ is the kernel\n",
        "- $g(x,y)$ is the output pixel value at position $(x,y)$\n"
      ],
      "metadata": {
        "id": "f40ggejBvJxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Padding** refer to adding extra pixels around the image to control how much the output shrinks after convolution. It is used to preserve the image size after the convolution.\n",
        "\n",
        "Types of padding:\n",
        "- Valid padding --> no padding, no extra pixels added\n",
        "- Same padding --> extra pixels added to preserve the image size\n",
        "\n",
        "\n",
        "**Stride** controls how much the kernel moves at each step when scanning the image (if 1, the kernel moves one pixel after another)."
      ],
      "metadata": {
        "id": "zvsc9LQGx2yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a kernel (Sobel filter)\n",
        "kernel = np.array([[-1, 0, 1],\n",
        "                   [-2, 0, 2],\n",
        "                   [-1, 0, 1]])\n",
        "\n",
        "# apply convolution without padding (valid padding) (stride supposed to be 1)\n",
        "output_valid = cv2.filter2D(image, -1, kernel)\n",
        "output_valid = output_valid[1:-1, 1:-1]  # crop edges manually to match the expected size\n",
        "\n",
        "# apply convolution with zero padding (same padding) (stride supposed to be 1)\n",
        "padded_image = cv2.copyMakeBorder(image, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0)  # adds border\n",
        "output_same = cv2.filter2D(padded_image, -1, kernel)\n",
        "output_same = output_same[1:-1, 1:-1]  # crop back to original size\n",
        "\n",
        "original_size = image.shape\n",
        "valid_size = output_valid.shape\n",
        "padded_size = padded_image.shape\n",
        "same_size = output_same.shape\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f'Original Image\\n{original_size[1]}x{original_size[0]}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(output_valid, cmap='gray')\n",
        "plt.title(f'Without Padding (Valid)\\n{valid_size[1]}x{valid_size[0]}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(output_same, cmap='gray')\n",
        "plt.title(f'With Padding (Same)\\n{same_size[1]}x{same_size[0]}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jxpcmQkHyFLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To compute the output size:**\n",
        "\n",
        "$$W_{out} = \\frac{(W-K+2P)}{S}+1$$\n",
        "$$H_{out} = \\frac{(H-K+2P)}{S}+1$$\n",
        "\n",
        "where:\n",
        "- $W$ is the original image width\n",
        "- $H$ is the original image height\n",
        "- $K$ is the kernel size\n",
        "- $P$ is the padding ($P=0$ if valid padding, $P=\\frac{(K-1)S}{2}$ if same padding)\n",
        "- $S$ is the stride\n",
        "\n",
        "Check with the above images!"
      ],
      "metadata": {
        "id": "Rot6zITc2afP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image gradients"
      ],
      "metadata": {
        "id": "tW1NTfxGQozV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image gradients detect and point to the areas where there is a rapid change in intensity, like edges.\n",
        "\n",
        "$$âˆ‡_{xy}I = [\\frac{\\partial I[x,y]}{\\partial x}, \\frac{\\partial I[x,y]}{\\partial y}]$$"
      ],
      "metadata": {
        "id": "3Vafepj3esN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sobel filter and Derivative of Gaussian (DoG)"
      ],
      "metadata": {
        "id": "zxWVBEYzoT83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Sobel filter is used to approximate the derivative of the image in the x and y directions"
      ],
      "metadata": {
        "id": "k-qaYnj-oVrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Horizontal Sobel filter (x direction)\n",
        "$$\n",
        "\\frac{1}{8}\n",
        "\\begin{bmatrix}\n",
        "-1 & 0 & 1 \\\\\n",
        "-2 & 0 & 2 \\\\\n",
        "-1 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Vertical Sobel filter (y direction)\n",
        "$$\n",
        "\\frac{1}{8}\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 1 \\\\\n",
        "0 & 0 & 0 \\\\\n",
        "-1 & -2 & -1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "<br>\n",
        "The $\\frac{1}{8}$ is needed to get the right gradient magnitude."
      ],
      "metadata": {
        "id": "pgYbDMOpd8MY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derivative of Gaussian (DoG): Apply the Gaussian filter to the image to reduce the noise, and then compute the gradient of the image.\n",
        "\n",
        "NOTE: the Sobel filter is the most common approximation of the DoG."
      ],
      "metadata": {
        "id": "70smKeWIgINR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image in grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# compute the Sobel gradients in X and Y directions\n",
        "sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)  # derivative in x direction\n",
        "sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)  # derivative in y direction\n",
        "\n",
        "# compute the magnitude and direction of the gradient\n",
        "gradient_magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
        "gradient_direction = cv2.phase(sobel_x, sobel_y, angleInDegrees=True)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(gradient_magnitude, cmap='gray')\n",
        "plt.title('Derivative of Gaussian')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(gradient_direction, cmap='hsv')\n",
        "plt.title('Gradient Direction')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VRto1F_pQrfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laplacian filter"
      ],
      "metadata": {
        "id": "XeRZ4LPypori"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a second derivative filter, working with the Laplacian operator:\n",
        "\n",
        "$$âˆ‡^2I=\\frac{âˆ‚^2I}{âˆ‚x^2}+\\frac{âˆ‚^2I}{âˆ‚y^2}$$"
      ],
      "metadata": {
        "id": "H74Jl0E3g7yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the Laplacian filter\n",
        "laplacian = cv2.Laplacian(gray_image, cv2.CV_64F)\n",
        "\n",
        "# convert the result to uint8 (for visualization)\n",
        "laplacian_abs = cv2.convertScaleAbs(laplacian)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.imshow(laplacian_abs, cmap='gray')\n",
        "plt.title('Laplacian Filter')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SyTy_VwRpqia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laplacian of Gaussian (LoG)"
      ],
      "metadata": {
        "id": "KwQ7KYp4qgRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the Laplacian is highly sensitive to noise, we apply a Gaussian filter to the image to reduce the noise and the Laplacian filter to detect edges."
      ],
      "metadata": {
        "id": "yeZhJpjfjG9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = 1.0  # adjust sigma for different levels of smoothing\n",
        "gaussian_blurred = cv2.GaussianBlur(gray_image, (5, 5), sigma)\n",
        "\n",
        "laplacian_of_gaussian = cv2.Laplacian(gaussian_blurred, cv2.CV_64F)\n",
        "\n",
        "# convert the result to uint8 (for visualization purposes)\n",
        "log_result = cv2.convertScaleAbs(laplacian_of_gaussian)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(log_result, cmap='gray')\n",
        "plt.title('Laplacian of Gaussian')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zWnfU-IGqfqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Canny-edge detector"
      ],
      "metadata": {
        "id": "0uoMmyijrSCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computer vision pipeline whose steps are:\n",
        "\n",
        "\n",
        "1.   Filter the image with DoG\n",
        "2.   Find the magnitude and orientation of the gradient\n",
        "3.   Non-maximum suppression (Each pixel is compared to its two neighbors in the gradient direction, and weaker ones are suppressed to not consider noisy pixels)\n",
        "4.   Define two thresholds: low and high\n",
        "5.   Use the high threshold to start edge curves and the low threshold to\n",
        "     continue them"
      ],
      "metadata": {
        "id": "JbDOFqaPj6mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_threshold = 100  # lower threshold for edge detection\n",
        "high_threshold = 300  # upper threshold for edge detection, this should be 3 times the low_threshold\n",
        "edges = cv2.Canny(gray_image, low_threshold, high_threshold)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Canny Edge Detection')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wlXDWozIrWBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of edge detection methods:"
      ],
      "metadata": {
        "id": "K9VW8aa23-Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- **DoG**: medium noise reduction, medium accuracy, low complexity\n",
        "- **Laplacian**: low noise reduction, low accuracy, low complexity\n",
        "- **LoG**: high noise reduction, high accuracy, medium complexity\n",
        "- **Canny**: very high noise reduction, very high accuracy, high complexity"
      ],
      "metadata": {
        "id": "I62JAg2D2tBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Harris corner detector"
      ],
      "metadata": {
        "id": "vTkyLXE84zTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corner detection technique consisting of shifting a predefined window over the image. Such a window detects significant changes in all directions."
      ],
      "metadata": {
        "id": "wgSWFql07o4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "- Compute Gaussian derivatives at each pixel\n",
        "- Compute the second moment matrix H in a Gaussian window around each pixel\n",
        "- Compute the corner response function\n",
        "- Find local maxima of response function (non-maximum suppression)\n",
        "\n",
        "\n",
        "Parameters of the cornerharris function:\n",
        "- gray_float: gray scale image\n",
        "- blockSize: size of neighbourhood considered for corner detection\n",
        "- ksize: Sobel kernel size for the Gaussian derivatives\n",
        "- k: is a free parameter. the lower, the more corners are detected with lower accuracy. The higher, the less corners are detected with higher accuracy"
      ],
      "metadata": {
        "id": "O7sTtOOP6MKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"image.jpg\")  # Replace with your image path\n",
        "b,g,r = cv2.split(image)\n",
        "image = cv2.merge([r,g,b])\n",
        "\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "gray_float = np.float32(gray_image)\n",
        "\n",
        "# apply Harris Corner Detector\n",
        "harris_response = cv2.cornerHarris(gray_float, blockSize=2, ksize=3, k=0.04)\n",
        "\n",
        "# threshold the response to identify strong corners\n",
        "threshold = 0.01 * harris_response.max()\n",
        "image[harris_response > threshold] = [0, 0, 255]  # Mark corners in blues\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(image)\n",
        "plt.title(\"Harris Corner Detection\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HUGX0jLkAFrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Properties of Harris-corner detector:\n",
        "- equivariant to translation and rotation. âœ…\n",
        "- not equivariant to scaling. âŒ"
      ],
      "metadata": {
        "id": "jDzMabTZ7DTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example with rotated image"
      ],
      "metadata": {
        "id": "FGMIbizI9bPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"image.jpg\")  # Replace with your image path\n",
        "b,g,r = cv2.split(image)\n",
        "image = cv2.merge([r,g,b])\n",
        "\n",
        "# image rotation\n",
        "(h, w) = image.shape[:2]\n",
        "center = (w // 2, h // 2)  # image center\n",
        "angle = 45  # rotation angle\n",
        "scale = 1.0  # we can scale if we want\n",
        "\n",
        "rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "\n",
        "# apply the rotation\n",
        "rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
        "\n",
        "gray_rotated = cv2.cvtColor(rotated_image, cv2.COLOR_RGB2GRAY)\n",
        "gray_float_rotated = np.float32(gray_rotated)\n",
        "\n",
        "harris_response_rotated = cv2.cornerHarris(gray_float_rotated, blockSize=2, ksize=3, k=0.04)\n",
        "\n",
        "threshold = 0.01 * harris_response_rotated.max()\n",
        "rotated_image[harris_response_rotated > threshold] = [0, 0, 255]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(rotated_image)\n",
        "plt.title(\"Harris Corner Detection on Rotated Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mFqM4SQmgDUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example with scaled image"
      ],
      "metadata": {
        "id": "kXzi1uDL9epI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"image.jpg\")\n",
        "b,g,r = cv2.split(image)\n",
        "image = cv2.merge([r,g,b])\n",
        "\n",
        "# scale the image\n",
        "scale_factor = 0.2  # scale factor\n",
        "new_size = (int(image.shape[1] * scale_factor), int(image.shape[0] * scale_factor))\n",
        "scaled_image = cv2.resize(image, new_size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "gray_scaled = cv2.cvtColor(scaled_image, cv2.COLOR_RGB2GRAY)\n",
        "gray_float_scaled = np.float32(gray_scaled)\n",
        "\n",
        "harris_response_scaled = cv2.cornerHarris(gray_float_scaled, blockSize=2, ksize=3, k=0.04)\n",
        "\n",
        "threshold = 0.01 * harris_response_scaled.max()\n",
        "scaled_image[harris_response_scaled > threshold] = [0, 0, 255]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(scaled_image)\n",
        "plt.title(\"Harris Corner Detection on Scaled Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wpyKvUwl7zkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brief introduction to image pyramids"
      ],
      "metadata": {
        "id": "sLlfHD_7OWuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image pyramids are algorithms consisting of processing and scaling the given image, so to get a sort of pyramid.\n",
        "\n",
        "The pyramid is made up of octaves, and each octave is made up of a certain number of differently blurred versions (different sigmas) of the given image.\n",
        "\n",
        "images belonging to the same octave have the same scale. The upper we go, the higher is the image scaled.\n",
        "\n",
        "![Description](https://docs.opencv.org/4.x/Pyramids_Tutorial_Pyramid_Theory.png)"
      ],
      "metadata": {
        "id": "iOQ7DK25ObTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two main image Pyramids: Gaussian pyramid (for feature detection and matching) and Laplacian pyramid (for image reconstruction)\n",
        "\n",
        "Gaussian pyramid algorithm.\n",
        "- repeat until a minimum resolution is reached\n",
        "  - apply the Gaussian filter\n",
        "  - subsample the obtained image\n",
        "\n",
        "Laplacian pyramid algorithm.\n",
        "- repeat until a minimum resolution is reached\n",
        "  - apply the Gaussian filter\n",
        "  - compute the residual between the blurred images of step $t$ and $t-1$\n",
        "  - subsample the obtained image"
      ],
      "metadata": {
        "id": "1xnSEeE3Oi4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('image.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# number of levels in the pyramid\n",
        "num_levels = 4\n",
        "\n",
        "# construct the Gaussian Pyramid\n",
        "gaussian_pyramid = [image]  # start with the original image\n",
        "for i in range(num_levels):\n",
        "    image = cv2.pyrDown(image)  # downsample using Gaussian filter\n",
        "    gaussian_pyramid.append(image)\n",
        "\n",
        "# construct the Laplacian Pyramid\n",
        "laplacian_pyramid = []\n",
        "for i in range(num_levels, 0, -1):\n",
        "    gaussian_expanded = cv2.pyrUp(gaussian_pyramid[i])  # upsample to match previous level\n",
        "    gaussian_expanded = cv2.resize(gaussian_expanded, (gaussian_pyramid[i-1].shape[1], gaussian_pyramid[i-1].shape[0]))  # match size\n",
        "    laplacian = cv2.subtract(gaussian_pyramid[i-1], gaussian_expanded)  # compute Laplacian\n",
        "    laplacian_pyramid.append(laplacian)\n",
        "\n",
        "fig, axes = plt.subplots(2, num_levels + 1, figsize=(15, 6))\n",
        "\n",
        "for i in range(num_levels + 1):\n",
        "    axes[0, i].imshow(gaussian_pyramid[i])\n",
        "    axes[0, i].set_title(f'Gaussian {i}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "for i in range(num_levels):\n",
        "    axes[1, i].imshow(laplacian_pyramid[i], cmap='gray')\n",
        "    axes[1, i].set_title(f'Laplacian {i}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "axes[1, -1].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tPsZSdfkOaEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fourier series"
      ],
      "metadata": {
        "id": "rzpV7kMBcLDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Fourier's Claim\n",
        "\n",
        "The **fundamental claim** of Fourier is:\n",
        "> *Any periodic signal can be represented as the sum of multiple sinusoids with different frequencies, amplitudes, and phases.*\n",
        "\n",
        "Translated into mathematical terms, these **elementary blocks** are:\n",
        "\n",
        "$$A \\sin(2\\pi f x + \\phi)$$\n",
        "\n",
        "Where:\n",
        "- **Amplitude** ($A$): how strong the wave is;\n",
        "- **Frequency** ($f$): how fast it oscillates;\n",
        "- **Variable** ($x$): time or space;\n",
        "- **Phase** ($\\phi$): how shifted the wave is.\n",
        "\n",
        "By combining enough of these components, we can approximate any periodic function, no matter how complex.\n"
      ],
      "metadata": {
        "id": "5i_HxSshZTO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Signal definition in time domain\n",
        "duration = 2.5 # [s]\n",
        "sampling_rate = 1000  # [Hz]\n",
        "N = int(duration * sampling_rate)  # Number of samples\n",
        "t = np.linspace(0, duration, N, endpoint=False)\n",
        "\n",
        "# Frequency components definition\n",
        "frequencies = [3, 5, 7, 11]  # [Hz]\n",
        "amplitudes = [1.0, 0.8, 0.6, 0.4]  # Amplitudes\n",
        "phases = [0, np.pi/4, np.pi/2, np.pi]  # Initial phases [rad]\n",
        "colors = ['red', 'blue', 'green', 'purple']  # Colors for each component\n",
        "\n",
        "# Composite signal\n",
        "sinusoids = [A * np.sin(2 * np.pi * f * t + p) for A, f, p in zip(amplitudes, frequencies, phases)]\n",
        "signal = sum(sinusoids)\n",
        "\n",
        "# 3D plot\n",
        "fig = go.Figure()\n",
        "time_extension = 1.1  # Visualization problem solver :)\n",
        "\n",
        "# Add sinusoids components in the plot\n",
        "for i, (f, sinusoid, color) in enumerate(zip(frequencies, sinusoids, colors)):\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "          x = t,\n",
        "          y = np.full_like(t, f),\n",
        "          z = sinusoid,\n",
        "          mode = 'lines',\n",
        "          name = f'Sinusoid {f} Hz',\n",
        "          line = dict(color = color)\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Add composite signal in the plot\n",
        "fig.add_trace(\n",
        "    go.Scatter3d(\n",
        "        x = t,\n",
        "        y = np.full_like(t, 0),\n",
        "        z = signal,\n",
        "        mode = 'lines',\n",
        "        name = 'Composite Signal',\n",
        "        line = dict(width = 4, color = 'orange')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add frequency compentents in the plot\n",
        "for i, (f, color, amp) in enumerate(zip(frequencies, colors, amplitudes)):\n",
        "    # Frequency point\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x = [duration * time_extension],\n",
        "            y = [f],\n",
        "            z = [amp],\n",
        "            mode = 'markers',\n",
        "            name = f'Frequency {f} Hz',\n",
        "            marker = dict(size = 5, color = color)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Vertical bar connecting dots to frequency axis\n",
        "    fig.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x = [duration * time_extension, duration * time_extension],\n",
        "            y = [f, f],\n",
        "            z = [0, amp],\n",
        "            mode = 'lines',\n",
        "            line = dict(color = color, width = 3),\n",
        "            showlegend = False\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Add a reference dashed axis for zero amplitude in frequency domain\n",
        "fig.add_trace(\n",
        "    go.Scatter3d(\n",
        "        x = [duration * time_extension, duration * time_extension],\n",
        "        y = [0, max(frequencies) + 2],\n",
        "        z = [0, 0],\n",
        "        mode = 'lines',\n",
        "        line = dict(color = 'black', width = 2, dash = 'dash'),\n",
        "        name = 'Zero Amplitude Axis'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Final figure layout\n",
        "fig.update_layout(\n",
        "    scene = dict(\n",
        "        xaxis_title = \"Time [s]\",\n",
        "        yaxis_title = \"Frequency [Hz]\",\n",
        "        zaxis_title = \"Amplitude\",\n",
        "        camera = dict(eye = dict(x = 1.5, y = 1.5, z = 1.0))\n",
        "    ),\n",
        "    title = \"Time Signal Frequency Decomposition\",\n",
        "    width = 1400,\n",
        "    height = 950\n",
        ")\n",
        "\n",
        "fig.show(renderer = \"colab\")"
      ],
      "metadata": {
        "id": "J9v2wezihqGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fourier_approximation(t, num_components=5, signal_type='square'):\n",
        "    \"\"\"\n",
        "    Calculate the Fourier series approximation for different types of signals\n",
        "    ensuring exactly num_components are returned\n",
        "    \"\"\"\n",
        "    y = np.zeros_like(t)\n",
        "    components = []\n",
        "    frequencies = []\n",
        "\n",
        "    if signal_type == 'square':\n",
        "        \"\"\"\n",
        "          Square wave: sum of odd sinusoids with amplitude 1/n,\n",
        "          so we need to count only odd harmonics\n",
        "        \"\"\"\n",
        "        n = 1\n",
        "        count = 0\n",
        "        while count < num_components:\n",
        "            term = (4/np.pi) * (1/n) * np.sin(n * t)\n",
        "            y += term\n",
        "            components.append(term)\n",
        "            frequencies.append(n)\n",
        "            count += 1\n",
        "            n += 2\n",
        "        target = np.sign(np.sin(t))\n",
        "\n",
        "    elif signal_type == 'sawtooth':\n",
        "        \"\"\"\n",
        "          Sawtooth wave: all harmonics with alternating signs and amplitude 1/n\n",
        "        \"\"\"\n",
        "        for n in range(1, num_components + 1):\n",
        "            term = (2/np.pi) * ((-1)**(n+1) / n) * np.sin(n * t)\n",
        "            y += term\n",
        "            components.append(term)\n",
        "            frequencies.append(n)\n",
        "        target = 2 * (t/(2*np.pi) - np.floor(t/(2*np.pi) + 0.5))\n",
        "\n",
        "    elif signal_type == 'triangle':\n",
        "        \"\"\"\n",
        "          Triangle wave: sum of odd sinusoids with alternating signs and\n",
        "          amplitude 1/nÂ², so we need to count only odd harmonics\n",
        "        \"\"\"\n",
        "        n = 1\n",
        "        count = 0\n",
        "        while count < num_components:\n",
        "            term = (8/(np.pi**2)) * ((-1)**((n-1)//2) / (n**2)) * np.sin(n * t)\n",
        "            y += term\n",
        "            components.append(term)\n",
        "            frequencies.append(n)\n",
        "            count += 1\n",
        "            n += 2\n",
        "        target = 2 * np.abs((t - np.pi/2) % (2*np.pi) / np.pi - 1) - 1\n",
        "\n",
        "    return y, components, frequencies, target\n",
        "\n",
        "def plot_fourier_series(num_components=5, signal_type='square'):\n",
        "    t = np.linspace(0, 4 * np.pi, 1000) # [s]\n",
        "    y, components, frequencies, target = fourier_approximation(t, num_components, signal_type)\n",
        "\n",
        "    # Figure\n",
        "    fig = plt.figure(figsize=(18, 8))\n",
        "    gs = GridSpec(1, 3, width_ratios=[1, 1, 1])\n",
        "\n",
        "    # First plot: Sum of components (approximation) vs. target signal\n",
        "    ax1 = fig.add_subplot(gs[0])\n",
        "    ax1.plot(t, target, 'k--', label='Target signal')\n",
        "    ax1.plot(t, y, 'r-', linewidth=2, label=f'Approximation (n={num_components})')\n",
        "    ax1.set_title('Fourier Series Approximation')\n",
        "    ax1.set_xlabel('Time (s)')\n",
        "    ax1.set_ylabel('Amplitude')\n",
        "    ax1.grid(True)\n",
        "    ax1.set_xlim(0, 4 * np.pi)\n",
        "    ax1.legend()\n",
        "\n",
        "    # Second plot: Individual sinusoidal components\n",
        "    ax2 = fig.add_subplot(gs[1])\n",
        "    component_height = 1.0 / len(components)\n",
        "\n",
        "    for i, component in enumerate(components):\n",
        "        # Scale the component for better visualization\n",
        "        scaled_component = component * 0.4 * component_height\n",
        "\n",
        "        # Position each component in a space in the plot\n",
        "        position = 1.0 - (i + 0.5) * component_height\n",
        "        ax2.plot(t, scaled_component + position, label=f'Component {frequencies[i]}')\n",
        "\n",
        "        # Add a horizontal line to separate components\n",
        "        ax2.axhline(y=1.0 - (i+1) * component_height, color='gray', linestyle='-', alpha=0.3)\n",
        "\n",
        "    ax2.set_title(f'Sinusoidal Components ({len(components)} shown)')\n",
        "    ax2.set_xlabel('Time (s)')\n",
        "    ax2.set_yticks([])\n",
        "    ax2.set_xlim(0, 4 * np.pi)\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Third plot: Frequency spectrum (amplitude vs. frequency)\n",
        "    ax3 = fig.add_subplot(gs[2])\n",
        "\n",
        "    # Calculate amplitudes for each frequency\n",
        "    amplitudes = []\n",
        "    for i, freq in enumerate(frequencies):\n",
        "        if signal_type == 'square':\n",
        "            amplitudes.append((4/np.pi) * (1/freq))\n",
        "        elif signal_type == 'sawtooth':\n",
        "            amplitudes.append((2/np.pi) * ((-1)**(freq+1) / freq))\n",
        "        elif signal_type == 'triangle':\n",
        "            amplitudes.append((8/(np.pi**2)) * ((-1)**((freq-1)//2) / (freq**2)))\n",
        "\n",
        "    # Display the discrete spectrum\n",
        "    ax3.grid(True, zorder=0)\n",
        "    ax3.bar(frequencies, np.abs(amplitudes), alpha=0.8, color='blue', zorder=3)\n",
        "    ax3.set_title('Frequency Spectrum')\n",
        "    ax3.set_xlabel('Frequency (Hz)')\n",
        "    ax3.set_ylabel('Amplitude')\n",
        "    ax3.set_xticks(frequencies)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Interactive widgets to control parameters\n",
        "@interact\n",
        "def interactive_fourier(\n",
        "    num_components=IntSlider(min=1, max=20, step=1, value=5, description='Components:'),\n",
        "    signal_type=widgets.Dropdown(\n",
        "        options=[('Square wave', 'square'), ('Sawtooth wave', 'sawtooth'), ('Triangle wave', 'triangle')],\n",
        "        value='square',\n",
        "        description='Signal type:'\n",
        "    )\n",
        "):\n",
        "    plot_fourier_series(num_components, signal_type)"
      ],
      "metadata": {
        "id": "PyUCC7i813gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering signals\n",
        "In the frequency representation of a signal, each component carries specific information:\n",
        "\n",
        "- **Low frequencies** represent the **smooth, global structure** of the signal.\n",
        "- **High frequencies** capture the **sharp details and rapid variations**.\n",
        "\n",
        "This means that by **filtering** out:\n",
        "  - High frequencies, we remove details and retain the general shape of the signal.\n",
        "  - Low frequencies, we remove the base structure and emphasizes fine details"
      ],
      "metadata": {
        "id": "ITlA2PEY12E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fourier_approximation_filtered(t, num_components=5, signal_type='square', filter_range=(0, 20)):\n",
        "    y = np.zeros_like(t)\n",
        "    components = []\n",
        "    frequencies = []\n",
        "\n",
        "    if signal_type == 'square':\n",
        "        \"\"\"\n",
        "          Square wave: sum of odd sinusoids with amplitude 1/n,\n",
        "          so we need to count only odd harmonics\n",
        "        \"\"\"\n",
        "        n = 1\n",
        "        count = 0\n",
        "        while count < num_components:\n",
        "            term = (4/np.pi) * (1/n) * np.sin(n * t)\n",
        "            if filter_range[0] <= n <= filter_range[1]:\n",
        "                y += term\n",
        "            components.append(term)\n",
        "            frequencies.append(n)\n",
        "            count += 1\n",
        "            n += 2\n",
        "        target = np.sign(np.sin(t))\n",
        "\n",
        "    elif signal_type == 'sawtooth':\n",
        "        \"\"\"\n",
        "          Sawtooth wave: all harmonics with alternating signs and amplitude 1/n\n",
        "        \"\"\"\n",
        "        n = 1\n",
        "        count = 0\n",
        "        while count < num_components:\n",
        "            term = (2/np.pi) * ((-1)**(n+1) / n) * np.sin(n * t)\n",
        "            if filter_range[0] <= n <= filter_range[1]:\n",
        "                y += term\n",
        "            components.append(term)\n",
        "            frequencies.append(n)\n",
        "            count += 1\n",
        "            n += 1\n",
        "        target = 2 * (t/(2*np.pi) - np.floor(t/(2*np.pi) + 0.5))\n",
        "\n",
        "    elif signal_type == 'triangle':\n",
        "        \"\"\"\n",
        "          Triangle wave: sum of odd sinusoids with alternating signs and\n",
        "          amplitude 1/nÂ², so we need to count only odd harmonics\n",
        "        \"\"\"\n",
        "        n = 1\n",
        "        count = 0\n",
        "        while count < num_components:\n",
        "            term = (8/(np.pi**2)) * ((-1)**((n-1)//2) / (n**2)) * np.sin(n * t)\n",
        "            if filter_range[0] <= n <= filter_range[1]:\n",
        "                y += term\n",
        "            components.append(term)\n",
        "            frequencies.append(n)\n",
        "            count += 1\n",
        "            n += 2\n",
        "        target = 2 * np.abs((t - np.pi/2) % (2*np.pi) / np.pi - 1) - 1\n",
        "\n",
        "    return y, components, frequencies, target, filter_range\n",
        "\n",
        "def plot_fourier_series_filtered(num_components=5, signal_type='square', filter_range=(0, 20)):\n",
        "    t = np.linspace(0, 4 * np.pi, 1000) # [s]\n",
        "    y, components, frequencies, target, filter_range = fourier_approximation_filtered(t, num_components, signal_type, filter_range)\n",
        "\n",
        "    # Figure\n",
        "    fig = plt.figure(figsize=(18, 8))\n",
        "    gs = GridSpec(1, 3, width_ratios=[1, 1, 1])\n",
        "\n",
        "    # First plot: Sum of components (approximation) vs. target signal\n",
        "    ax1 = fig.add_subplot(gs[0])\n",
        "    ax1.plot(t, target, 'k--', label='Target signal')\n",
        "    ax1.plot(t, y, 'r-', linewidth=2, label=f'Filtered approx. (n={num_components})')\n",
        "    ax1.set_title('Fourier Series Approximation')\n",
        "    ax1.set_xlabel('Time (s)')\n",
        "    ax1.set_ylabel('Amplitude')\n",
        "    ax1.grid(True)\n",
        "    ax1.set_xlim(0, 4 * np.pi)\n",
        "    ax1.legend()\n",
        "\n",
        "    # Second plot: Individual sinusoidal components\n",
        "    ax2 = fig.add_subplot(gs[1])\n",
        "    component_height = 1.0 / max(len(components), 1)\n",
        "\n",
        "    for i, (component, freq) in enumerate(zip(components, frequencies)):\n",
        "        # Scale the component for better visualization\n",
        "        scaled_component = component * 0.4 * component_height\n",
        "\n",
        "        # Position each component in a space in the plot\n",
        "        position = 1.0 - (i + 0.5) * component_height\n",
        "\n",
        "        # Determine if this component is filtered out\n",
        "        is_filtered = filter_range[0] <= freq <= filter_range[1]\n",
        "\n",
        "        # Plot component\n",
        "        if is_filtered:\n",
        "            ax2.plot(t, scaled_component + position, label=f'Component {freq}')\n",
        "        else:\n",
        "            # Gray out filtered components\n",
        "            ax2.plot(t, scaled_component + position, color='gray', alpha=0.4, label=f'Component {freq} (filtered)')\n",
        "\n",
        "        # Add a horizontal line to separate components\n",
        "        ax2.axhline(y=1.0 - (i+1) * component_height, color='gray', linestyle='-', alpha=0.3)\n",
        "\n",
        "    ax2.set_title(f'Sinusoidal Components ({len(components)} shown)')\n",
        "    ax2.set_xlabel('Time (s)')\n",
        "    ax2.set_yticks([])\n",
        "    ax2.set_xlim(0, 4 * np.pi)\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Third plot: Frequency spectrum (amplitude vs. frequency) with filter visualization\n",
        "    ax3 = fig.add_subplot(gs[2])\n",
        "\n",
        "    # Calculate amplitudes for each frequency\n",
        "    amplitudes = []\n",
        "    for i, freq in enumerate(frequencies):\n",
        "        if signal_type == 'square':\n",
        "            amplitudes.append((4/np.pi) * (1/freq))\n",
        "        elif signal_type == 'sawtooth':\n",
        "            amplitudes.append((2/np.pi) * ((-1)**(freq+1) / freq))\n",
        "        elif signal_type == 'triangle':\n",
        "            amplitudes.append((8/(np.pi**2)) * ((-1)**((freq-1)//2) / (freq**2)))\n",
        "\n",
        "    # Display the discrete spectrum with filter visualization\n",
        "    ax3.grid(True, zorder=0)\n",
        "\n",
        "    # Draw out-filter region as a light blue rectangle\n",
        "    max_amplitude = max(np.abs(amplitudes)) if amplitudes else 1\n",
        "    filter_height = max_amplitude * 1.2\n",
        "    rect = plt.Rectangle((0, 0), max(frequencies) + 1, filter_height,\n",
        "                         facecolor='lightblue', alpha=0.3, zorder=1)\n",
        "    ax3.add_patch(rect)\n",
        "\n",
        "    # Draw the filter cut-off regions\n",
        "    left_rect = plt.Rectangle((0, 0), filter_range[0], filter_height,\n",
        "                             facecolor='red', alpha=0.2, zorder=2)\n",
        "    right_rect = plt.Rectangle((filter_range[1], 0), max(frequencies) + 1 - filter_range[1], filter_height,\n",
        "                              facecolor='red', alpha=0.2, zorder=2)\n",
        "    ax3.add_patch(left_rect)\n",
        "    ax3.add_patch(right_rect)\n",
        "\n",
        "    # Plot spectrum bars with appropriate colors based on filtering\n",
        "    for i, (freq, amp) in enumerate(zip(frequencies, amplitudes)):\n",
        "        if filter_range[0] <= freq <= filter_range[1]:\n",
        "            ax3.bar(freq, np.abs(amp), alpha=0.8, color='blue', zorder=3)\n",
        "        else:\n",
        "            # Gray out filtered frequencies\n",
        "            ax3.bar(freq, np.abs(amp), alpha=0.4, color='gray', zorder=3)\n",
        "\n",
        "    ax3.set_title('Frequency Spectrum with Filter')\n",
        "    ax3.set_xlabel('Frequency (Hz)')\n",
        "    ax3.set_ylabel('Amplitude')\n",
        "    ax3.set_xlim(0, max(frequencies) + 1)\n",
        "    ax3.set_xticks(frequencies)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Interactive widgets to control parameters\n",
        "@interact\n",
        "def interactive_fourier_filtered(\n",
        "    num_components=IntSlider(min=1, max=20, step=1, value=5, description='Components:'),\n",
        "    signal_type=widgets.Dropdown(\n",
        "        options=[('Square wave', 'square'), ('Sawtooth wave', 'sawtooth'), ('Triangle wave', 'triangle')],\n",
        "        value='square',\n",
        "        description='Signal type:'\n",
        "    ),\n",
        "    filter_range=FloatRangeSlider(\n",
        "        value=[0, 50],\n",
        "        min=0,\n",
        "        max=50,\n",
        "        step=1,\n",
        "        description='Filter [Hz]:',\n",
        "        disabled=False,\n",
        "        continuous_update=False,\n",
        "        orientation='horizontal',\n",
        "        readout=True,\n",
        "        readout_format='.0f',\n",
        "    )\n",
        "):\n",
        "    plot_fourier_series_filtered(num_components, signal_type, filter_range)"
      ],
      "metadata": {
        "id": "V2S6jiry-3kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Exaggerate!\n",
        "\n",
        "To further explore how Fourier series work, letâ€™s take a look at some **more extreme applications**:\n",
        "\n",
        "ðŸ”— **[Fourier Epicycles](https://www.myfourierepicycles.com/)** â€“ A visualization showing how Fourier series can reconstruct **complex drawings** using rotating circles.  \n",
        "ðŸŽ¥ **[Fourier Series Visualization](https://www.youtube.com/watch?v=r6sGWTCMz2k)** â€“ A fantastic animation demonstrating how sinusoids combine to form intricate shapes (until drawing Fourier itself ðŸ™‚)\n"
      ],
      "metadata": {
        "id": "sU8qpt3v4m3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why was 1D Important?\n",
        "\n",
        "Everything we have explored in **1D Fourier series** forms the foundation for understanding **2D Fourier Transform** in future applications.\n",
        "\n",
        "- In **1D**, we analyzed how different frequencies contribute to a **signal**.\n",
        "- We saw that **low frequencies** define the overall shape, while **high frequencies** capture finer details.\n",
        "- **Filtering in 1D** helped us understand how removing specific frequencies affects the reconstruction."
      ],
      "metadata": {
        "id": "kaB4baUREWN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before Moving On: The True Fourier Series\n",
        "\n",
        "So far, we have introduced the **Fourier Series** conceptually as a sum of elementary blocks of the form:\n",
        "\n",
        "$$ A \\sin(2\\pi f t + \\phi) $$\n",
        "\n",
        "This representation helped us understand that a periodic signal is **composed of sinusoids** with different frequencies, amplitudes, and phases.\n",
        "\n",
        "However, this is not the **canonical mathematical expression** of the Fourier Series. The true formulation is:\n",
        "\n",
        "$$ s(t) = \\frac{a_0}{2} + \\sum_{k=1}^{\\infty} \\left( a_k \\cos(2\\pi f k t) + b_n \\sin(2\\pi f k t) \\right) $$\n",
        "\n",
        "Where:\n",
        "- $ \\frac{a_0}{2} $ represents the average value of the function over the period $T$.\n",
        "- $ a_k $ and $ b_k $ are the **Fourier coefficients**, which determine how much each cosine and sine component contributes.\n",
        "- $ f = \\frac{1}{T} $ is the **fundamental frequency** of the signal.\n",
        "- $ k $ is the **harmonic index**, meaning each term corresponds to a multiple of the fundamental frequency.\n",
        "\n",
        "This formula expresses any periodic function as a combination of sine and cosine waves (the sinusoids of the Fourier's claim), whose frequencies are determined by the function's period.\n",
        "\n",
        "The Fourier Series can be expressed also in complex form:\n",
        "$$ s(t) = \\sum_{k=-\\infty}^{\\infty} c_n e^{j 2\\pi k f t} $$\n",
        "\n",
        "Where:\n",
        "- $ c_n $ are the **complex coefficients** that contain information about the amplitude and phase of each frequency component."
      ],
      "metadata": {
        "id": "162_xFbP_d8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fourier Transform"
      ],
      "metadata": {
        "id": "L1-k_iVSfsfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Transformation, Unbound by Time\n",
        "\n",
        "The **Fourier Transform** allows us to obtain the **frequency representation** of any signal, revealing:\n",
        "- **Which frequencies are present** in the signal.\n",
        "- **How strong** each frequency component is.\n",
        "\n",
        "In mathematical terms, it converts a signal from the **time domain** to the **frequency domain**, giving us a complete view of its spectral composition.\n",
        "\n",
        "$$ \\mathcal{F} \\{ f(t) \\} = F(f) = \\int_{-\\infty}^{+\\infty} f(t) e^{-j 2\\pi f t} dt $$\n",
        "\n",
        "The **Fourier Transform** output is a function in a **complex domain**. To recover the original real-valued signal, we use the **Inverse Fourier Transform**:\n",
        "\n",
        "$$ \\mathcal{F} \\{ F(f) \\}^{-1} = f(t) = \\int_{-\\infty}^{+\\infty} F(f) e^{j 2\\pi f t} df $$\n",
        "\n",
        "The **symmetry properties** of the Fourier Transform ensure that when applying the inverse transform, the result is real-valued (if the original function was real).\n",
        "\n",
        "Thus, the Fourier Transform serves as a bridge between real-world signals and the complex domain of frequency analysis, allowing operations to be performed across different domains. This proves particularly useful in certain contexts.\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?export=download&id=11xYvGceXhcDCFWdG_T7O2WGKHN9UMtmd\" width=\"500\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "9nIzvA2mwOsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beyond Periodicity\n",
        "\n",
        "We have seen how the **Fourier Series** allows us to express periodic signals as sums of sinusoids with different frequencies, amplitudes, and phases. But what if the signal is **not periodic**?\n",
        "\n",
        "This is where the **Fourier Transform** comes in.\n",
        "\n",
        "With that tool, it is possible to \"update\" the previous Fourier claim:\n",
        "> *Any signal, periodic or not, can be represented in terms of its frequency components using the Fourier Transform.*\n",
        "\n"
      ],
      "metadata": {
        "id": "rvjWAyocHkYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_signal(fs=1000, N=1000, f1=50, f2=120, f3=200, a1=1.0, a2=0.5, a3=0.75, noise_level=0.2):\n",
        "    T = 1 / fs  # Sampling period\n",
        "    t = np.linspace(0, (N - 1) * T, N)  # Time vector\n",
        "\n",
        "    # Create the signal as the sum of three sinusoids\n",
        "    signal = a1 * np.sin(2 * np.pi * f1 * t) + \\\n",
        "             a2 * np.sin(2 * np.pi * f2 * t) + \\\n",
        "             a3 * np.sin(2 * np.pi * f3 * t)\n",
        "\n",
        "    # Add Gaussian noise\n",
        "    np.random.seed(42)\n",
        "    noise = noise_level * np.random.normal(0, 1, N)\n",
        "    noisy_signal = signal + noise\n",
        "\n",
        "    return t, noisy_signal, [(f1, a1), (f2, a2), (f3, a3)]\n",
        "\n",
        "def compute_fft(signal, fs, N):\n",
        "    yf = fft(signal)\n",
        "    xf = fftfreq(N, 1/fs)[:N//2]\n",
        "    amplitude_spectrum = 2.0 / N * np.abs(yf[:N//2])\n",
        "\n",
        "    return xf, amplitude_spectrum\n",
        "\n",
        "def plot_signal_analysis(fs=1000, N=1000, f1=50, f2=120, f3=200, a1=1.0, a2=0.5, a3=0.75, noise_level=0.2):\n",
        "    t, noisy_signal, true_values = generate_signal(fs, N, f1, f2, f3, a1, a2, a3, noise_level)\n",
        "    xf, amplitude_spectrum = compute_fft(noisy_signal, fs, N)\n",
        "\n",
        "    # Identify peak frequencies\n",
        "    threshold = 0.3  # Threshold for detecting peaks\n",
        "    detected_frequencies = [(freq, round(amp, 3)) for freq, amp in zip(xf, amplitude_spectrum) if amp > threshold]\n",
        "\n",
        "    # Figure\n",
        "    fig = plt.figure(figsize=(18, 6))\n",
        "    fig.suptitle(\n",
        "        \"Fourier Transform of a Noisy Signal Composed of Multiple Periodic Components\",\n",
        "        weight = \"bold\",\n",
        "        fontsize = 16\n",
        "    )\n",
        "    gs = GridSpec(1, 2, width_ratios=[1, 1])\n",
        "\n",
        "    # Time-domain plot\n",
        "    ax1 = fig.add_subplot(gs[0])\n",
        "    ax1.plot(t, noisy_signal, color='b')\n",
        "    ax1.set_title('Time Domain')\n",
        "    ax1.set_xlabel('Time [s]')\n",
        "    ax1.set_ylabel('Amplitude')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Frequency spectrum plot\n",
        "    ax2 = fig.add_subplot(gs[1])\n",
        "    ax2.plot(xf, amplitude_spectrum, color='r')\n",
        "    ax2.set_title('Frequency Spectrum')\n",
        "    ax2.set_xlabel('Frequency [Hz]')\n",
        "    ax2.set_ylabel('Amplitude')\n",
        "    ax2.grid(True)\n",
        "    ax2.set_xlim(0, fs/2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Table for expected vs detected values\n",
        "    table = PrettyTable(\n",
        "        [\n",
        "            \"\\033[1mExpected Frequency (Hz)\\033[0m\",\n",
        "            \"\\033[1mExpected Amplitude\\033[0m\",\n",
        "            \"\\033[1mDetected Frequency (Hz)\\033[0m\",\n",
        "            \"\\033[1mDetected Amplitude\\033[0m\"\n",
        "        ]\n",
        "    )\n",
        "    expected_freqs, expected_amps = zip(*true_values)\n",
        "    detected_freqs, detected_amps = zip(*detected_frequencies) if detected_frequencies else ([], [])\n",
        "\n",
        "    for i in range(len(expected_freqs)):\n",
        "        detected_freq = detected_freqs[i] if i < len(detected_freqs) else 'N/A'\n",
        "        detected_amp = detected_amps[i] if i < len(detected_amps) else 'N/A'\n",
        "        table.add_row([expected_freqs[i], expected_amps[i], detected_freq, detected_amp])\n",
        "\n",
        "    print(table)\n",
        "\n",
        "plot_signal_analysis()"
      ],
      "metadata": {
        "id": "Dh1lw75aH6hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_time_vector(fs=1000, N=1000):\n",
        "    T = 1 / fs  # Sampling period\n",
        "    return np.arange(-N//2, N//2) * T\n",
        "\n",
        "def compute_fft(signal, fs, N):\n",
        "    yf = fftshift(fft(signal))\n",
        "    xf = fftshift(fftfreq(N, 1/fs))\n",
        "    amplitude_spectrum = np.abs(yf) / N\n",
        "    return xf, amplitude_spectrum\n",
        "\n",
        "def plot_signal_and_fft(signal, time_title, freq_title, t, fs, N, ax_time, ax_freq):\n",
        "    xf, amplitude_spectrum = compute_fft(signal, fs, N)\n",
        "\n",
        "    # Time-domain plot\n",
        "    ax_time.plot(t, signal, color='b', linewidth=1.5)\n",
        "    ax_time.set_title(time_title)\n",
        "    ax_time.set_xlabel('Time [s]')\n",
        "    ax_time.set_ylabel('Amplitude')\n",
        "    ax_time.grid(True)\n",
        "\n",
        "    # Frequency-domain plot\n",
        "    ax_freq.plot(xf, amplitude_spectrum, color='r', linewidth=1.5)\n",
        "    ax_freq.set_title(freq_title)\n",
        "    ax_freq.set_xlabel('Frequency [Hz]')\n",
        "    ax_freq.set_ylabel('Amplitude')\n",
        "    ax_freq.grid(True)\n",
        "\n",
        "def plot_all_signals(fs=1000, N=1000):\n",
        "    t = generate_time_vector(fs, N)\n",
        "\n",
        "    # Define signals\n",
        "    rect_width = 0.1\n",
        "    rect_signal = np.zeros_like(t)\n",
        "    rect_signal[np.abs(t) < rect_width/2] = 1.0\n",
        "\n",
        "    sigma = 0.05\n",
        "    gaussian_signal = np.exp(-0.5 * (t/sigma)**2)\n",
        "\n",
        "    alpha = 100\n",
        "    step_signal = np.heaviside(t, 1)\n",
        "\n",
        "    # Figure\n",
        "    fig = plt.figure(figsize=(18, 9))\n",
        "    fig.suptitle(\n",
        "        \"Fourier Transform of Canonical Aperiodic Signals\",\n",
        "        weight = \"bold\",\n",
        "        fontsize = 16\n",
        "    )\n",
        "    gs = GridSpec(3, 2, width_ratios=[1, 1])\n",
        "\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    ax3 = fig.add_subplot(gs[1, 0])\n",
        "    ax4 = fig.add_subplot(gs[1, 1])\n",
        "    ax5 = fig.add_subplot(gs[2, 0])\n",
        "    ax6 = fig.add_subplot(gs[2, 1])\n",
        "\n",
        "    plot_signal_and_fft(\n",
        "        rect_signal,\n",
        "        \"Rectangular Pulse - Time Domain\",\n",
        "        \"Sinc Function - Frequency Domain\",\n",
        "        t, fs, N, ax1, ax2\n",
        "    )\n",
        "    plot_signal_and_fft(\n",
        "        gaussian_signal,\n",
        "        \"Gaussian Pulse - Time Domain\",\n",
        "        \"Gaussian Function - Frequency Domain\",\n",
        "        t, fs, N, ax3, ax4\n",
        "    )\n",
        "    plot_signal_and_fft(\n",
        "        step_signal,\n",
        "        \"Step Function - Time Domain\",\n",
        "        \"Transformed Step - Frequency Domain\",\n",
        "        t, fs, N, ax5, ax6\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_all_signals()"
      ],
      "metadata": {
        "id": "eNWykscCIEhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Fourier Series vs Fourier Transform: The (Student's) inevitable Question\n",
        "\n",
        "1. **The Fourier Series is a special case of the Fourier Transform.**  \n",
        "   - The Fourier Series applies **only to periodic signals**, producing a **discrete spectrum**.\n",
        "   - The Fourier Transform applies to **any signal**, producing a **continuous spectrum**.\n",
        "\n",
        "2. **They are NOT inverse operations!**  \n",
        "   - The Fourier Series is not the inverse of the Fourier Transform.\n",
        "\n",
        "\\\\\n",
        "\n",
        "|  | **Fourier Series** | **Fourier Transform** |\n",
        "|---|------------------|--------------------|\n",
        "| **Input** | **Periodic signal in time domain** $ s(t) $ | **Any signal in time domain** $ f(t) $ |\n",
        "| **Output** | **Periodic function in time domain** (sum of sinusoids) | **Complex function in frequency domain** $ F(f) $ |\n",
        "| **Definition** | Represents a **periodic signal** as a sum of sinusoids at harmonic frequencies | Decomposes **any signal** into its frequency components |\n",
        "| **Frequencies** | **Discrete** (multiples of a fundamental frequency) | **Continuous** (any frequency value) |\n",
        "| **Formula** | $$ s(t) = \\sum_{k=-\\infty}^{\\infty} c_k e^{j 2\\pi k f t} $$ | $$ F(f) = \\int_{-\\infty}^{+\\infty} f(t) e^{-j 2\\pi f t} dt $$ |\n",
        "\n",
        "\\\\"
      ],
      "metadata": {
        "id": "p__4V0QU2WGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discrete Fourier Transform\n",
        "\n"
      ],
      "metadata": {
        "id": "l8A4FBr14MNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Continuous to Computable\n",
        "The **Fourier Transform** is a powerful tool for analyzing signals in the **frequency domain**. However, in practical applicationsâ€”especially in **computer vision, audio processing, and numerical computing**â€”we often deal with **discrete** data rather than continuous functions.\n",
        "\n",
        "This is where the **Discrete Fourier Transform (DFT)** comes into play.\n",
        "\n",
        "The DFT is the discrete counterpart of the Fourier Transform, defined for a **finite sequence** of $ N $ samples:\n",
        "\n",
        "$$ X_k = \\sum_{n=0}^{N-1} x_n e^{\\frac{-j 2\\pi k n}{N}}, \\quad k = 0, 1, ..., N-1 $$\n",
        "\n",
        "Where:\n",
        "- $ x_n $ represents the sample of input signal in the **time domain**.\n",
        "- $ X_k $ represents the sample of output in the **frequency domain**.\n",
        "- $ N $ is the number of discrete samples.\n",
        "- $ k $ is the frequency bin.\n",
        "- The exponential term $ e^{-j 2\\pi k n / N} $ represents the contribution of each frequency component.\n",
        "\n",
        "In this case, we can interpret $ k/N $ as the **normalized frequency**, corresponding to the continuous frequency in the Fourier Transform. Similarly, $ n $ represents the **discrete time index**, which relates to the continuous time variable in the original signal.\n",
        "\n",
        "\n",
        "Since real-world data is often **sampled** rather than continuous, the **DFT is essential** because **computers process discrete signals**, so we cannot apply the continuous Fourier Transform directly."
      ],
      "metadata": {
        "id": "cCk5xtCd08Bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complex... but Simple!\n",
        "\n",
        "The **Discrete Fourier Transform (DFT)** allows us to express a discrete signal in terms of its frequency components. However, before diving into its interpretation, it is crucial to recognize a fundamental fact:\n",
        "\n",
        "### 1ï¸âƒ£ **Each $X_k$ is Simply a Complex Number**\n",
        "The DFT formula consists of a summation of weighted complex exponentials:\n",
        "\n",
        "$$ X_k = \\sum_{n=0}^{N-1} x_n e^{\\frac{-j 2\\pi k n}{N}} $$\n",
        "\n",
        "Rewriting the exponent:\n",
        "\n",
        "$$ X_k = \\sum_{n=0}^{N-1} x_n e^{-j b_n} $$\n",
        "\n",
        "Expanding the summation:\n",
        "\n",
        "$$ X_k = x_0 e^{-j b_0} + x_1 e^{-j b_1} + ... + x_{N-1} e^{-jb_{N-1}} = A_k + j B_k $$\n",
        "\n",
        "This means that **the output of the DFT at each $k$ is nothing more than a complex number**, composed of:\n",
        "- A **real part** $A_k$.\n",
        "- An **imaginary part** $B_k$.\n",
        "\n",
        "---\n",
        "\n",
        "### 2ï¸âƒ£ **Representing $X_k$ in the Frequency Domain**\n",
        "Since $X_k$ is a complex number, to visualize it in the **frequency domain**, we use the standard representation of complex numbers in terms of **magnitude** and **phase**:\n",
        "\n",
        "- **Magnitude** (strength of the frequency component):\n",
        "\n",
        "  $$ |X_k| = \\sqrt{A_k^2 + B_k^2} $$\n",
        "\n",
        "- **Phase** (how the frequency component is shifted):\n",
        "\n",
        "  $$ \\angle X_k = \\theta $$\n",
        "\n",
        "This conversion allows us to express each $X_k$ in a way that is **meaningful in the frequency domain**, rather than just as real and imaginary parts.\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?export=download&id=1-mIlEcSPJ_x74-646eAjkGFDiEFYLCQP\" width=\"500\">\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "### 3ï¸âƒ£ **Repeating This Process for Every $k$**\n",
        "By repeating this process for every $k$, we obtain **two plots** that fully describe the signal in the frequency domain:\n",
        "\n",
        "1. **Magnitude Spectrum**: A plot of $|X_k|$, showing the contribution of each frequency.\n",
        "2. **Phase Spectrum**: A plot of $\\angle X_k$, indicating how each frequency component is shifted in time.\n",
        "\n",
        "Together, these two plots provide **a complete representation of the signal's frequency content**, relative to its original sampled version in the time domain. Thus, the DFT does not output anything mysterious, just a sequence of complex numbers, whose magnitude and phase tell us how the frequencies combine to form the original signal.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wwzin-DM2PiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fs = 10  # Sampling frequency [Hz]\n",
        "T = 2.0  # Duration [s]\n",
        "N = int(T * fs)  # Number of samples\n",
        "t = np.linspace(0, T, N, endpoint=False)  # Time\n",
        "\n",
        "# Continuos signal\n",
        "def f(t):\n",
        "  return 5 + 2 * np.cos(2 * np.pi * t - np.pi/2) + 3 * np.cos(4 * np.pi * t)\n",
        "signal = f(t)\n",
        "\n",
        "# Calculate DFT\n",
        "fft_result = fft(signal)\n",
        "fft_freq = np.fft.fftfreq(N, 1/fs)\n",
        "\n",
        "# Calculate magnitude and phase\n",
        "magnitude = np.abs(fft_result) / N  # Normalization\n",
        "phase = np.angle(fft_result, deg=True)\n",
        "\n",
        "# Visualization stuff\n",
        "positive_freq_indices = np.where(fft_freq >= 0)[0]\n",
        "min_display_magnitude = 0.01\n",
        "for i in range(len(magnitude)):\n",
        "    if magnitude[i] < min_display_magnitude:\n",
        "        magnitude[i] = min_display_magnitude\n",
        "\n",
        "def plot_fft(freq_idx=0):\n",
        "    # Figure\n",
        "    plt.clf()\n",
        "    fig = plt.figure(figsize=(18, 10))\n",
        "    gs = GridSpec(2, 2)\n",
        "\n",
        "    # First plot: original continuous and sampled function\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    t_continuous = np.linspace(0, T, 1000)\n",
        "    signal_continuous = f(t_continuous)\n",
        "    ax1.plot(t_continuous, signal_continuous, 'b-', linewidth=2, label='Continuous Signal')\n",
        "    ax1.plot(t, signal, 'ro', markersize=8, label='Samples')\n",
        "    ax1.set_xlabel('Time (s)')\n",
        "    ax1.set_ylabel('Amplitude')\n",
        "    ax1.set_title('Original Signal f(t) and Samples')\n",
        "    ax1.grid(True)\n",
        "    ax1.legend()\n",
        "\n",
        "    # Second plot: DFT magnitude\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    markerline, stemlines, baseline = ax2.stem(\n",
        "        fft_freq[positive_freq_indices],\n",
        "        magnitude[positive_freq_indices],\n",
        "        'purple',\n",
        "        markerfmt='mo',\n",
        "        basefmt=\" \"\n",
        "    )\n",
        "    plt.setp(stemlines, 'linewidth', 2)\n",
        "\n",
        "    # Highlight selected frequency\n",
        "    selected_idx = positive_freq_indices[freq_idx]\n",
        "    ax1.plot(t[selected_idx], signal[selected_idx], 'yo', markersize=10)\n",
        "    ax2.plot(fft_freq[selected_idx], magnitude[selected_idx], 'yo', markersize=10)\n",
        "\n",
        "    ax2.set_xlabel('Frequency (Hz)')\n",
        "    ax2.set_ylabel('Amplitude')\n",
        "    ax2.set_title('DFT Magnitude')\n",
        "    ax2.set_xlim(-0.5, fs/2 + 0.5)\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Third plot: phase of DFT\n",
        "    ax3 = fig.add_subplot(gs[1, 0])\n",
        "    markerline, stemlines, baseline = ax3.stem(\n",
        "        fft_freq[positive_freq_indices],\n",
        "        phase[positive_freq_indices],\n",
        "        'g', markerfmt='go', basefmt=\" \"  # Remove baseline\n",
        "    )\n",
        "    plt.setp(stemlines, 'linewidth', 2)\n",
        "\n",
        "    # Highlight selected frequency\n",
        "    ax3.plot(fft_freq[selected_idx], phase[selected_idx], 'yo', markersize=10)\n",
        "    ax3.set_xlabel('Frequency (Hz)')\n",
        "    ax3.set_ylabel('Phase (degrees)')\n",
        "    ax3.set_title('DFT Phase')\n",
        "    ax3.set_xlim(-0.5, fs/2 + 0.5)\n",
        "    ax3.grid(True)\n",
        "\n",
        "    # Fourth plot: complex plane\n",
        "    ax4 = fig.add_subplot(gs[1, 1])\n",
        "    ax4.set_aspect('equal')\n",
        "    ax4.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    ax4.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "\n",
        "    # Unit circle\n",
        "    theta = np.linspace(0, 2*np.pi, 100)\n",
        "    ax4.plot(np.cos(theta), np.sin(theta), 'k--', alpha=0.3)\n",
        "\n",
        "    # Plot frequency components in complex plane\n",
        "    for i, idx in enumerate(positive_freq_indices):\n",
        "        re = magnitude[idx] * np.cos(np.radians(phase[idx]))\n",
        "        im = magnitude[idx] * np.sin(np.radians(phase[idx]))\n",
        "        ax4.plot([0, re], [0, im], 'b-', alpha=0.3)\n",
        "        ax4.plot(re, im, 'bo', alpha=0.5)\n",
        "\n",
        "    # Highlight selected component in complex plane\n",
        "    re_selected = magnitude[selected_idx] * np.cos(np.radians(phase[selected_idx]))\n",
        "    im_selected = magnitude[selected_idx] * np.sin(np.radians(phase[selected_idx]))\n",
        "    ax4.plot([0, re_selected], [0, im_selected], 'y-', linewidth=2)\n",
        "    ax4.plot(re_selected, im_selected, 'yo', markersize=10)\n",
        "\n",
        "    freq_value = fft_freq[selected_idx]\n",
        "    mag_value = magnitude[selected_idx]\n",
        "    phase_value = phase[selected_idx]\n",
        "    original_mag = np.abs(fft_result[selected_idx]) / N\n",
        "\n",
        "    ax4.text(0.05, 0.95, f'Frequency: {freq_value:.2f} Hz', transform=ax4.transAxes)\n",
        "    ax4.text(0.05, 0.9, f'Magnitude: {original_mag:.4f}', transform=ax4.transAxes)\n",
        "    ax4.text(0.05, 0.85, f'Phase: {phase_value:.2f}Â°', transform=ax4.transAxes)\n",
        "\n",
        "    ax4.set_xlabel('Real Part')\n",
        "    ax4.set_ylabel('Imaginary Part')\n",
        "    ax4.set_title('Complex Plane Representation')\n",
        "    ax4.grid(True)\n",
        "\n",
        "    max_mag = np.max(magnitude) * 1.2\n",
        "    ax4.set_xlim(-max_mag, max_mag)\n",
        "    ax4.set_ylim(-max_mag, max_mag)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Interactive plot\n",
        "slider = IntSlider(\n",
        "    min=0,\n",
        "    max=len(positive_freq_indices)-1,\n",
        "    step=1,\n",
        "    value=0,\n",
        "    description='Sample:',\n",
        "    continuous_update=False,\n",
        "    layout={'width': '400px'}\n",
        ")\n",
        "\n",
        "print(\"Use the slider below to select different frequency components:\")\n",
        "interact(plot_fft, freq_idx=slider)"
      ],
      "metadata": {
        "id": "Yw7gmOdJIg6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŽ¥ **For further insights:** [DFT Visualization](https://www.youtube.com/watch?v=mkGsMWi_j4Q)  "
      ],
      "metadata": {
        "id": "FIJ8vQzF9SNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency domain for Computer Vision"
      ],
      "metadata": {
        "id": "hZ5nnDAX1jdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What Changes in 2D?\n",
        "\n",
        "In **2D**, the same logic applies, but now we analyze **images** instead of 1D signals.  \n",
        "\n",
        "A greyscale image can be thought of as a **2D discrete signal**, where:\n",
        "- The **spatial dimensions** (rows and columns) correspond to **time samples** in the 1D case.\n",
        "- Each pixel value represents an **amplitude**, similar to how a signal varies in time.\n",
        "\n",
        "Unlike in the **1D case**, where we obtained a **1D magnitude and phase plot**, the **2D Discrete Fourier Transform (DFT)** produces:\n",
        "\n",
        "- A **2D magnitude spectrum**, representing how much of each spatial frequency is present in the image.\n",
        "  - **Bright areas** indicate **strong frequency components**, meaning there are prominent repeating patterns or edges in those spatial directions.\n",
        "  - **Dark areas** represent **low energy**, meaning little variation in those frequencies.\n",
        "- A **2D phase spectrum**, indicating how different frequency components are shifted spatially.\n",
        "  - The phase contains information about **spatial shifts** in the image.\n",
        "  - Unlike the magnitude, which is easier to interpret, the phase is more abstract but is crucial for reconstructing the original image.\n",
        "\n",
        "In these graphs, the low frequencies are concentrated towards the center of the images, while the high frequencies are located towards the edges."
      ],
      "metadata": {
        "id": "EqSGKrSuDLqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fft_analysis(image):\n",
        "    f = np.fft.fft2(image)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    magnitude_spectrum = np.abs(fshift)\n",
        "    phase_spectrum = np.angle(fshift)\n",
        "    return fshift, magnitude_spectrum, phase_spectrum\n",
        "\n",
        "def reconstruct_image(magnitude, phase):\n",
        "    complex_spectrum = magnitude * np.exp(1j * phase)\n",
        "    f_ishift = np.fft.ifftshift(complex_spectrum)\n",
        "    img_reconstructed = np.fft.ifft2(f_ishift)\n",
        "    return np.abs(img_reconstructed)\n",
        "\n",
        "# Convert to grayscale\n",
        "image_bw = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# Compute image DFT\n",
        "fshift, magnitude, phase = fft_analysis(image_bw)\n",
        "image_mag = reconstruct_image(magnitude, np.zeros_like(phase))\n",
        "image_phase = reconstruct_image(np.ones_like(magnitude), phase)\n",
        "\n",
        "# Figure\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Original image\n",
        "axes[0].imshow(image_bw, cmap='gray')\n",
        "axes[0].set_title(\"Original Image\")\n",
        "\n",
        "# Magnitude spectrum\n",
        "axes[1].imshow(np.log(1 + magnitude), cmap='viridis')\n",
        "axes[1].set_title(\"Magnitude Spectrum\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Phase spectrum\n",
        "axes[2].imshow(phase, cmap='viridis')\n",
        "axes[2].set_title(\"Phase Spectrum\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kfbfPFvBgu_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dft_analysis(image):\n",
        "    dft = np.fft.fft2(image)\n",
        "    dft_shift = np.fft.fftshift(dft)\n",
        "    magnitude = np.abs(dft_shift)\n",
        "    phase = np.angle(dft_shift)\n",
        "    return dft_shift, magnitude, phase\n",
        "\n",
        "def scale_image(image, scale_factor):\n",
        "    new_size = (int(image.shape[1] * scale_factor), int(image.shape[0] * scale_factor))\n",
        "    scaled_image = cv2.resize(image, new_size, interpolation=cv2.INTER_CUBIC)\n",
        "    return scaled_image\n",
        "\n",
        "# Image DFT\n",
        "dft_shift, magnitude, phase = dft_analysis(image_bw)\n",
        "\n",
        "# Scaled image\n",
        "scale_factor = 0.09\n",
        "image_scaled = scale_image(image_bw, scale_factor)\n",
        "\n",
        "# Scaled image DFT\n",
        "dft_shift_scaled, magnitude_scaled, phase_scaled = dft_analysis(image_scaled)\n",
        "\n",
        "# Figure\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
        "\n",
        "# Original image\n",
        "axes[0, 0].imshow(image_bw, cmap='gray')\n",
        "axes[0, 0].set_title(\"Original Image\")\n",
        "\n",
        "# Image magnitude\n",
        "axes[0, 1].imshow(np.log(1 + magnitude), cmap='viridis')\n",
        "axes[0, 1].set_title(\"Original Magnitude\")\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "# Image phase\n",
        "axes[0, 2].imshow(phase, cmap='viridis')\n",
        "axes[0, 2].set_title(\"Original Phase\")\n",
        "axes[0, 2].axis('off')\n",
        "\n",
        "# Scaled image\n",
        "axes[1, 0].imshow(image_scaled, cmap='gray')\n",
        "axes[1, 0].set_title(f\"Scaled Image (factor {scale_factor})\")\n",
        "\n",
        "# Scaled image magnitude\n",
        "axes[1, 1].imshow(np.log(1 + magnitude_scaled), cmap='viridis')\n",
        "axes[1, 1].set_title(\"Scaled Magnitude\")\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "# Scaled image phase\n",
        "axes[1, 2].imshow(phase_scaled, cmap='viridis')\n",
        "axes[1, 2].set_title(\"Scaled Phase\")\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hgeRZVidwUEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute 2D Fourier Transform\n",
        "dft = np.fft.fft2(image_bw)\n",
        "dft_shifted = np.fft.fftshift(dft)\n",
        "amplitude = np.abs(dft_shifted)\n",
        "phase = np.angle(dft_shifted)\n",
        "\n",
        "# Create filters for horizontal and vertical variations\n",
        "rows, cols = image_bw.shape\n",
        "crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "# Filter for vertical variations (keeps central horizontal frequencies)\n",
        "vert_mask = np.zeros((rows, cols), np.uint8)\n",
        "vert_mask[:, ccol-5:ccol+5] = 1\n",
        "\n",
        "# Filter for horizontal variations (keeps central vertical frequencies)\n",
        "horz_mask = np.zeros((rows, cols), np.uint8)\n",
        "horz_mask[crow-5:crow+5, :] = 1\n",
        "\n",
        "# Apply filters\n",
        "dft_vert = dft_shifted * vert_mask\n",
        "dft_horz = dft_shifted * horz_mask\n",
        "\n",
        "# Reconstruct filtered images\n",
        "def reconstruct_image(complex_dft):\n",
        "    complex_dft_unshifted = np.fft.ifftshift(complex_dft)\n",
        "    reconstructed = np.fft.ifft2(complex_dft_unshifted)\n",
        "    return np.real(reconstructed)\n",
        "\n",
        "image_vert = reconstruct_image(dft_vert)\n",
        "image_horz = reconstruct_image(dft_horz)\n",
        "\n",
        "# Normalize for visualization\n",
        "def normalize_image(img):\n",
        "    return (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "\n",
        "# Extract and normalize variations\n",
        "vertical_variations = np.diff(image_bw, axis=0)\n",
        "vertical_variations = np.vstack([vertical_variations, np.zeros((1, image_bw.shape[1]))])\n",
        "vertical_variations_norm = normalize_image(vertical_variations)\n",
        "\n",
        "horizontal_variations = np.diff(image_bw, axis=1)\n",
        "horizontal_variations = np.hstack([horizontal_variations, np.zeros((image_bw.shape[0], 1))])\n",
        "horizontal_variations_norm = normalize_image(horizontal_variations)\n",
        "\n",
        "# Prepare normalized images\n",
        "image_norm = normalize_image(image_bw)\n",
        "image_vert_norm = normalize_image(image_vert)\n",
        "image_horz_norm = normalize_image(image_horz)\n",
        "\n",
        "# Interactive visualization\n",
        "def plot_fft_variations(variation_type):\n",
        "    plt.figure(figsize=(24, 8))  # Increased figure size\n",
        "\n",
        "    if variation_type == \"Vertical Variations\":\n",
        "        images = [image_norm, vertical_variations_norm, image_vert_norm, np.log(1 + np.abs(dft_vert)), np.angle(dft_vert)]\n",
        "        titles = [\"Original Image\", \"Modified image (only Vertical Variations)\", \"Image without Vertical Variations\", \"Modified Image Magnitude\", \"Modified Image Phase\"]\n",
        "    else:\n",
        "        images = [image_norm, horizontal_variations_norm, image_horz_norm, np.log(1 + np.abs(dft_horz)), np.angle(dft_horz)]\n",
        "        titles = [\"Original Image\", \"Modified image (only Horizontal Variations)\", \"Image without Horizontal Variations\", \"Modified Image Magnitude\", \"Modified Image Phase\"]\n",
        "\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(images[i], cmap='gray' if i < 3 else 'viridis')\n",
        "        plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Dropdown menu\n",
        "dropdown = Dropdown(\n",
        "    options=[\"Vertical Variations\", \"Horizontal Variations\"],\n",
        "    value=\"Vertical Variations\",\n",
        "    description=\"Select:\",\n",
        "    layout=widgets.Layout(width='30%')\n",
        ")\n",
        "\n",
        "interact(plot_fft_variations, variation_type=dropdown);"
      ],
      "metadata": {
        "id": "FmKySfZLAeZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tool provides an intuitive way to grasp how manipulating the magnitude spectrum impacts the reconstructed image.\n",
        "\n",
        "ðŸ”— **[Live 2D FFT Visualization](https://monman53.github.io/2dfft/)**  "
      ],
      "metadata": {
        "id": "sDyTwNuHAua0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase is the key\n",
        "\n",
        "While it might seem intuitive to think that the **magnitude spectrum** carries most of the information about an image, experiments show that **the phase is actually the key component for reconstruction**. The phase spetrum encodes most of the structural and spatial information of an image.\n",
        "\n",
        "Creating **hybrid images** by swapping or combining magnitude and phase between different images:\n",
        "\n",
        "1. **The reconstructed image looks much more like the image from which the phase was taken, rather than the magnitude.**  \n",
        "   - This demonstrates that **the phase spectrum contains the primary structure of an image**, while the magnitude spectrum influences contrast and intensity distribution.\n",
        "\n",
        "2. **Magnitude alone does not carry the detailed image information.**  \n",
        "   - If an image is reconstructed using only the magnitude of one image and the phase of another, the result looks **more like the original phase image**.\n",
        "\n",
        "Thus, the phase spectrum is crucial for preserving the spatial relationships and structure of an image, whereas the magnitude primarily influences intensity variations.\n"
      ],
      "metadata": {
        "id": "NiILerMxfCbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O url1.jpg \"https://upload.wikimedia.org/wikipedia/commons/1/15/Red_Apple.jpg\"\n",
        "!wget -O url2.jpg \"https://upload.wikimedia.org/wikipedia/commons/3/36/Kyoho-grape.jpg\""
      ],
      "metadata": {
        "id": "MIgOwlTO3zhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_image(magnitude, phase):\n",
        "    complex_signal = magnitude * np.exp(1j * phase)\n",
        "    complex_signal = np.fft.ifftshift(complex_signal)\n",
        "    reconstructed = np.fft.ifft2(complex_signal)\n",
        "    return np.real(reconstructed)\n",
        "\n",
        "def normalize_image(img):\n",
        "    return (img - np.min(img)) / (np.max(img) - np.min(img)) * 255\n",
        "\n",
        "# Load and convert in greyscale the images\n",
        "image1 = cv2.cvtColor(cv2.imread(\"url1.jpg\"), cv2.COLOR_BGR2GRAY)\n",
        "image2 = cv2.cvtColor(cv2.imread(\"url2.jpg\"), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Resize images to the same dimensions\n",
        "min_shape = (min(image1.shape[0], image2.shape[0]), min(image1.shape[1], image2.shape[1]))\n",
        "image1 = cv2.resize(image1, (min_shape[1], min_shape[0]), interpolation=cv2.INTER_AREA)\n",
        "image2 = cv2.resize(image2, (min_shape[1], min_shape[0]), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# Apply DFT\n",
        "dft1 = np.fft.fft2(image1)\n",
        "dft2 = np.fft.fft2(image2)\n",
        "dft1_shifted = np.fft.fftshift(dft1)\n",
        "dft2_shifted = np.fft.fftshift(dft2)\n",
        "\n",
        "magnitude1 = np.abs(dft1_shifted)\n",
        "magnitude2 = np.abs(dft2_shifted)\n",
        "phase1 = np.angle(dft1_shifted)\n",
        "phase2 = np.angle(dft2_shifted)\n",
        "\n",
        "# Create hybrids\n",
        "\n",
        "# Magnitude from Image 1 + Phase from Image 2\n",
        "hybrid1 = reconstruct_image(magnitude1, phase2)\n",
        "\n",
        "# Magnitude from Image 2 + Phase from Image 10\n",
        "hybrid2 = reconstruct_image(magnitude2, phase1)\n",
        "\n",
        "# Sum of magnitudes + Phase from Image 1\n",
        "magnitude_sum = (magnitude1 + magnitude2) / 2\n",
        "hybrid3 = reconstruct_image(magnitude_sum, phase1)\n",
        "\n",
        "# Magnitude from Image 1 + Sum of phases\n",
        "phase_sum = (phase1 + phase2) / 2\n",
        "hybrid4 = reconstruct_image(magnitude1, phase_sum)\n",
        "\n",
        "hybrid1 = normalize_image(hybrid1)\n",
        "hybrid2 = normalize_image(hybrid2)\n",
        "hybrid3 = normalize_image(hybrid3)\n",
        "hybrid4 = normalize_image(hybrid4)\n",
        "\n",
        "# Figure\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# First row: original images\n",
        "plt.subplot(3, 2, 1)\n",
        "plt.imshow(image1, cmap='gray')\n",
        "plt.title('Image 1 (Apple)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.imshow(image2, cmap='gray')\n",
        "plt.title('Image 2 (Grape)')\n",
        "plt.axis('off')\n",
        "\n",
        "# Second row: Hybrids\n",
        "plt.subplot(3, 2, 3)\n",
        "plt.imshow(hybrid1, cmap='gray')\n",
        "plt.title('Magnitude Apple + Phase Grape')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.imshow(hybrid2, cmap='gray')\n",
        "plt.title('Magnitude Grape + Phase Apple')\n",
        "plt.axis('off')\n",
        "\n",
        "# Third row: new hybrids with sums\n",
        "plt.subplot(3, 2, 5)\n",
        "plt.imshow(hybrid3, cmap='gray')\n",
        "plt.title('Sum of magnitudes + Phase Apple')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3, 2, 6)\n",
        "plt.imshow(hybrid4, cmap='gray')\n",
        "plt.title('Magnitude Apple + Sum of Phases')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "At7L4pVbcbRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Convolve When You Can Multiply?\n",
        "\n",
        "One of the biggest advantages of using the **DFT in image processing** is how it simplifies **convolution**. Instead of performing **complex spatial operations**, we can simply **multiply** in the frequency domain.  \n",
        "\n",
        "$$G = \\mathcal{F}\\{g\\} = \\mathcal{F}\\{h \\star i\\} = \\mathcal{F}\\{h\\}\\mathcal{F}\\{i\\}= H * I$$\n",
        "\n",
        "The difference between the two scenario is marked:\n",
        "- Convolution in the **Spatial Domain**  \n",
        "  - Defined as the sum of **weighted neighboring pixels** using a filter kernel\n",
        "  - Requires **sliding a kernel** over the image, performing multiple multiplications and summations.Computationally **expensive** for large kernels and images.\n",
        "\n",
        "- Convolution in the **Frequency Domain**  \n",
        "  - Compute the **DFT** of the image $I$.  \n",
        "  - Compute the **DFT** of the filter kernel $H$.  \n",
        "  - Multiply their frequency representations:  \n",
        "  - Apply the **Inverse DFT** to get the final filtered image.  \n",
        "\n",
        "This drastically reduces computational complexity, making it **ideal for large filters**.\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?export=download&id=1fpFr7TfERlwOMBmg8McZIT8YIyVtpPMF\" width=\"500\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "jxmXM3DFah-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal\n",
        "\n",
        "fig = None\n",
        "axes = None\n",
        "image = cv2.imread('image.jpg')\n",
        "image_bw = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def plot_equivalence(img, kernel_type='gaussian'):\n",
        "    global fig, axes\n",
        "\n",
        "    # Create different kernels\n",
        "    if kernel_type == 'gaussian':\n",
        "        kernel = cv2.getGaussianKernel(25, 5)\n",
        "        kernel = kernel @ kernel.T\n",
        "        title = \"Gaussian Blur\"\n",
        "    elif kernel_type == 'high-pass':\n",
        "        kernel = np.ones((25, 25)) / (25*25)\n",
        "        kernel = -kernel\n",
        "        kernel[12, 12] = 1 + kernel[12, 12]\n",
        "        title = \"High-Pass Filter\"\n",
        "    elif kernel_type == 'low-pass':\n",
        "        kernel = np.ones((25, 25)) / (25*25)\n",
        "        title = \"Low-Pass Filter\"\n",
        "    elif kernel_type == 'band-pass':\n",
        "        kernel_low = cv2.getGaussianKernel(25, 5)\n",
        "        kernel_low = kernel_low @ kernel_low.T\n",
        "        kernel_high = cv2.getGaussianKernel(25, 1)\n",
        "        kernel_high = kernel_high @ kernel_high.T\n",
        "        kernel = kernel_low - kernel_high\n",
        "        kernel = kernel / np.sum(np.abs(kernel))\n",
        "        title = \"Band-Pass Filter\"\n",
        "    elif kernel_type == 'edge-detect':\n",
        "        kernel = np.array([[-1, -2, -1],\n",
        "                           [0,  0,  0],\n",
        "                           [1,  2,  1]])\n",
        "        title = \"Edge Detection\"\n",
        "\n",
        "\n",
        "    original_kernel = kernel.copy()\n",
        "    kernel = kernel / np.max(np.abs(kernel))\n",
        "    padded_kernel = np.zeros_like(img, dtype=float)\n",
        "    kh, kw = kernel.shape\n",
        "    padded_kernel[:kh, :kw] = kernel\n",
        "\n",
        "    # Spatial convolution\n",
        "    img_float = img.astype(float)\n",
        "    if img_float.max() > 1.0:  # Normalize if needed\n",
        "        img_float = img_float / 255.0\n",
        "\n",
        "    spatial_result = signal.convolve2d(img_float, kernel, mode='same', boundary='wrap')\n",
        "    if kernel_type == 'edge-detect':\n",
        "        spatial_result = np.abs(spatial_result)\n",
        "        spatial_result = spatial_result / np.max(spatial_result)\n",
        "        spatial_result = np.power(spatial_result, 0.5)  # Apply gamma correction to enhance edges\n",
        "\n",
        "    # Frequency domain\n",
        "    img_fft = np.fft.fft2(img_float)\n",
        "    img_fft_shifted = np.fft.fftshift(img_fft)\n",
        "\n",
        "    # Kernel DFT\n",
        "    kernel_fft = np.fft.fft2(np.fft.ifftshift(padded_kernel))\n",
        "    kernel_fft_shifted = np.fft.fftshift(kernel_fft)\n",
        "\n",
        "    # Convolution in frequency domain is multiplication\n",
        "    freq_result_fft = img_fft * kernel_fft\n",
        "    freq_result = np.real(np.fft.ifft2(freq_result_fft))\n",
        "    if kernel_type == 'edge-detect':\n",
        "        freq_result = np.abs(freq_result)\n",
        "        freq_result = freq_result / np.max(freq_result)\n",
        "        freq_result = np.power(freq_result, 0.5)  # Apply gamma correction to enhance edges\n",
        "\n",
        "    img_magnitude = np.log(1 + np.abs(img_fft_shifted))\n",
        "    kernel_magnitude = np.log(1 + np.abs(kernel_fft_shifted))\n",
        "    result_magnitude = np.log(1 + np.abs(np.fft.fftshift(freq_result_fft)))\n",
        "\n",
        "    img_magnitude = img_magnitude / np.max(img_magnitude)\n",
        "    kernel_magnitude = kernel_magnitude / np.max(kernel_magnitude)\n",
        "    result_magnitude = result_magnitude / np.max(result_magnitude)\n",
        "\n",
        "    # Create a new figure or clean the existing one\n",
        "    if fig is None or not plt.fignum_exists(fig.number):\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(14, 9))\n",
        "        plt.subplots_adjust(wspace=0.4, hspace=0.3, left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
        "    else:\n",
        "        for ax_row in axes:\n",
        "            for ax in ax_row:\n",
        "                ax.clear()\n",
        "\n",
        "    axes[0, 0].imshow(img_float, cmap='gray')\n",
        "    axes[0, 0].set_title('Original Image')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Visualization stuff\n",
        "    if kernel_type == 'low-pass':\n",
        "        display_kernel = original_kernel / np.max(original_kernel)\n",
        "    else:\n",
        "        display_kernel = original_kernel\n",
        "\n",
        "    axes[0, 1].imshow(display_kernel, cmap='gray')\n",
        "    axes[0, 1].set_title(f'Kernel: {title}')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[0, 2].imshow(spatial_result, cmap='gray')\n",
        "    axes[0, 2].set_title('Spatial Convolution Result')\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    axes[1, 0].imshow(img_magnitude, cmap='viridis')\n",
        "    axes[1, 0].set_title('Image DFT Magnitude')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    axes[1, 1].imshow(kernel_magnitude, cmap='viridis')\n",
        "    axes[1, 1].set_title('Kernel DFT Magnitude')\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    axes[1, 2].imshow(result_magnitude, cmap='viridis')\n",
        "    axes[1, 2].set_title('Frequency Domain Result Magnitude')\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "    if hasattr(fig, 'patches'):\n",
        "        for patch in fig.patches[:]:\n",
        "            if isinstance(patch, FancyArrowPatch):\n",
        "                patch.remove()\n",
        "\n",
        "    for artist in fig.texts[:]:\n",
        "        artist.remove()\n",
        "\n",
        "    fig.text(0.325, 0.755, '$\\\\star$', fontsize=24)  # Spatial convolution symbol\n",
        "    fig.text(0.330, 0.235, '$\\\\cdot$', fontsize=24)  # Frequency multiplication symbol\n",
        "    fig.text(0.655, 0.755, '$=$', fontsize=24)       # Spatial result equals\n",
        "    fig.text(0.653, 0.235, '$=$', fontsize=24)       # Frequency result equals\n",
        "\n",
        "    arrow1 = FancyArrowPatch(\n",
        "        (0.22, 0.56), (0.22, 0.44),\n",
        "        connectionstyle=\"arc3,rad=0\",\n",
        "        arrowstyle=\"-|>\",\n",
        "        mutation_scale=15,\n",
        "        color='blue',\n",
        "        transform=fig.transFigure\n",
        "    )\n",
        "    fig.text(0.18, 0.5, '$\\\\mathcal{F}$', fontsize=18)\n",
        "\n",
        "    arrow2 = FancyArrowPatch(\n",
        "        (0.78, 0.44), (0.78, 0.56),\n",
        "        connectionstyle=\"arc3,rad=0\",\n",
        "        arrowstyle=\"-|>\",\n",
        "        mutation_scale=15,\n",
        "        color='red',\n",
        "        transform=fig.transFigure\n",
        "    )\n",
        "    fig.text(0.80, 0.5, '$\\\\mathcal{F}^{-1}$', fontsize=18)\n",
        "\n",
        "    fig.patches.append(arrow1)\n",
        "    fig.patches.append(arrow2)\n",
        "\n",
        "    # Update the figure\n",
        "    plt.draw()\n",
        "\n",
        "    return spatial_result, freq_result\n",
        "\n",
        "def interactive_convolution(image):\n",
        "    global fig, axes\n",
        "\n",
        "    # Create dropdown widget\n",
        "    kernel_dropdown = widgets.Dropdown(\n",
        "        options=['gaussian', 'high-pass', 'low-pass', 'band-pass', 'edge-detect'],\n",
        "        value='gaussian',\n",
        "        description='Kernel Type:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    def update_plot(change):\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        display(kernel_dropdown)\n",
        "        plot_equivalence(image, change['new'])\n",
        "\n",
        "    kernel_dropdown.observe(update_plot, names='value')\n",
        "    display(kernel_dropdown)\n",
        "    plot_equivalence(image, 'gaussian')\n",
        "\n",
        "interactive_convolution(image_bw)"
      ],
      "metadata": {
        "id": "HE7FnS9aMN3l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}